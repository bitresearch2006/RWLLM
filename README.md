# RWLLM
Create the micro service for Large Language Model

LLM_enquiry.py = Generate response from model is executed in locally
LLM_model_download.py =  Download the model in local
